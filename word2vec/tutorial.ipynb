{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "here I implement word2vec with very simple example using tensorflow  \n",
    "word2vec is vector representation for words with similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "we will use only 10 sentences to create word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words\n",
    "In order for efficiency of creating word vector, we will remove commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(corpus):\n",
    "    stop_words = ['is', 'a', 'will', 'be']\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we have word set by which we will have word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy',\n",
       " 'girl',\n",
       " 'king',\n",
       " 'man',\n",
       " 'pretty',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'strong',\n",
       " 'wise',\n",
       " 'woman',\n",
       " 'young'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generation\n",
    "we will generate label for each word using skip gram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "\n",
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())\n",
    "    \n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king strong man\n",
      "queen wise woman\n",
      "boy young man\n",
      "girl young woman\n",
      "prince young king\n",
      "princess young queen\n",
      "man strong\n",
      "woman pretty\n",
      "prince boy king\n",
      "princess girl queen\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for text in corpus:\n",
    "    print(text)\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>king</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strong</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>queen</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>queen</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wise</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wise</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input   label\n",
       "0    king  strong\n",
       "1    king     man\n",
       "2  strong    king\n",
       "3  strong     man\n",
       "4     man    king\n",
       "5     man  strong\n",
       "6   queen    wise\n",
       "7   queen   woman\n",
       "8    wise   queen\n",
       "9    wise   woman"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy': 3,\n",
       " 'girl': 8,\n",
       " 'king': 0,\n",
       " 'man': 11,\n",
       " 'pretty': 7,\n",
       " 'prince': 10,\n",
       " 'princess': 6,\n",
       " 'queen': 4,\n",
       " 'strong': 9,\n",
       " 'wise': 2,\n",
       " 'woman': 1,\n",
       " 'young': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"king\", \"strong\"}, \n",
      "{\"king\", \"man\"}, \n",
      "{\"strong\", \"king\"}, \n",
      "{\"strong\", \"man\"}, \n",
      "{\"man\", \"king\"}, \n",
      "{\"man\", \"strong\"}, \n",
      "{\"queen\", \"wise\"}, \n",
      "{\"queen\", \"woman\"}, \n",
      "{\"wise\", \"queen\"}, \n",
      "{\"wise\", \"woman\"}, \n",
      "{\"woman\", \"queen\"}, \n",
      "{\"woman\", \"wise\"}, \n",
      "{\"boy\", \"young\"}, \n",
      "{\"boy\", \"man\"}, \n",
      "{\"young\", \"boy\"}, \n",
      "{\"young\", \"man\"}, \n",
      "{\"man\", \"boy\"}, \n",
      "{\"man\", \"young\"}, \n",
      "{\"girl\", \"young\"}, \n",
      "{\"girl\", \"woman\"}, \n",
      "{\"young\", \"girl\"}, \n",
      "{\"young\", \"woman\"}, \n",
      "{\"woman\", \"girl\"}, \n",
      "{\"woman\", \"young\"}, \n",
      "{\"prince\", \"young\"}, \n",
      "{\"prince\", \"king\"}, \n",
      "{\"young\", \"prince\"}, \n",
      "{\"young\", \"king\"}, \n",
      "{\"king\", \"prince\"}, \n",
      "{\"king\", \"young\"}, \n",
      "{\"princess\", \"young\"}, \n",
      "{\"princess\", \"queen\"}, \n",
      "{\"young\", \"princess\"}, \n",
      "{\"young\", \"queen\"}, \n",
      "{\"queen\", \"princess\"}, \n",
      "{\"queen\", \"young\"}, \n",
      "{\"man\", \"strong\"}, \n",
      "{\"strong\", \"man\"}, \n",
      "{\"woman\", \"pretty\"}, \n",
      "{\"pretty\", \"woman\"}, \n",
      "{\"prince\", \"boy\"}, \n",
      "{\"prince\", \"king\"}, \n",
      "{\"boy\", \"prince\"}, \n",
      "{\"boy\", \"king\"}, \n",
      "{\"king\", \"prince\"}, \n",
      "{\"king\", \"boy\"}, \n",
      "{\"princess\", \"girl\"}, \n",
      "{\"princess\", \"queen\"}, \n",
      "{\"girl\", \"princess\"}, \n",
      "{\"girl\", \"queen\"}, \n",
      "{\"queen\", \"princess\"}, \n",
      "{\"queen\", \"girl\"}, \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    print \"{\\\"\" + x + \"\\\", \\\"\" + y + \"\\\"}, \"\n",
    "    #print x, word2int[x], to_one_hot_encoding(word2int[x])\n",
    "    #print y, word2int[y], to_one_hot_encoding(word2int[y])\n",
    "    #print \"--------------------------------\"\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "print X_train\n",
    "print Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "(?, 12)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 12), dtype=float32)\n",
      "(?, 2)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# making placeholders for X_train and Y_train\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "print ONE_HOT_DIM\n",
    "print x.shape\n",
    "print y_label\n",
    "# word embedding will be 2 dimension for 2d visualization\n",
    "EMBEDDING_DIM = 2 \n",
    "\n",
    "# hidden layer: which represents word vector eventually\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "\n",
    "print hidden_layer.shape\n",
    "\n",
    "\n",
    "# output layer\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# loss function: cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "\n",
    "print loss\n",
    "# training operation\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9929936]\n",
      "[[-1.4802796   0.15112314]\n",
      " [ 1.3338461  -0.49326912]\n",
      " [ 0.5550914  -0.2848338 ]\n",
      " [ 0.210275    0.70763737]\n",
      " [-0.13345762 -1.7440417 ]\n",
      " [ 1.1965036  -1.8461531 ]\n",
      " [ 2.4143093  -1.000317  ]\n",
      " [-1.675049    0.8652733 ]\n",
      " [ 0.9013713   0.79454577]\n",
      " [ 0.44831207  0.5106683 ]\n",
      " [ 0.25280872  1.1923499 ]\n",
      " [ 1.2894003   0.64921486]]\n",
      "('iteration 0 loss is : ', 3.429049)\n",
      "('iteration 3000 loss is : ', 1.8469862)\n",
      "('iteration 6000 loss is : ', 1.7803186)\n",
      "('iteration 9000 loss is : ', 1.7491246)\n",
      "('iteration 12000 loss is : ', 1.7285994)\n",
      "('iteration 15000 loss is : ', 1.7168013)\n",
      "('iteration 18000 loss is : ', 1.7092603)\n",
      "('iteration 21000 loss is : ', 1.7035094)\n",
      "('iteration 24000 loss is : ', 1.6987923)\n",
      "('iteration 27000 loss is : ', 1.6947675)\n",
      "('iteration 30000 loss is : ', 1.6912434)\n",
      "('iteration 33000 loss is : ', 1.6881057)\n",
      "('iteration 36000 loss is : ', 1.6852797)\n",
      "('iteration 39000 loss is : ', 1.6827132)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "iteration = 40000\n",
    "vectors = sess.run(b1)\n",
    "print(vectors)\n",
    "vectors = sess.run(W1)\n",
    "print(vectors)\n",
    "    \n",
    "for i in range(iteration):\n",
    "    # input is X_train which is one hot encoded word\n",
    "    # label is Y_train which is one hot encoded neighbor word\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "\n",
    "    if i % 3000 == 0:\n",
    "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5094281]\n",
      "[[-1.2285161  -0.6267361 ]\n",
      " [-1.2727653  -1.8133893 ]\n",
      " [ 5.072935   -4.2561855 ]\n",
      " [-1.0526576  -0.14354265]\n",
      " [-0.7447506  -2.0368452 ]\n",
      " [-1.4453822  -1.3607126 ]\n",
      " [ 4.812353   -2.055343  ]\n",
      " [ 3.2475069  -5.134308  ]\n",
      " [ 0.1999776  -2.0853264 ]\n",
      " [ 1.0683353   6.182065  ]\n",
      " [ 2.2479002   5.2398214 ]\n",
      " [ 0.6121856   1.9054925 ]]\n",
      "[[ 0.28091204  0.88269204]\n",
      " [ 0.23666286 -0.30396116]\n",
      " [ 6.582363   -2.7467575 ]\n",
      " [ 0.45677054  1.3658855 ]\n",
      " [ 0.7646775  -0.52741706]\n",
      " [ 0.06404591  0.1487155 ]\n",
      " [ 6.321781   -0.54591477]\n",
      " [ 4.756935   -3.6248798 ]\n",
      " [ 1.7094058  -0.5758983 ]\n",
      " [ 2.5777636   7.691493  ]\n",
      " [ 3.7573285   6.7492495 ]\n",
      " [ 2.1216137   3.4149208 ]]\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
    "vectors = sess.run(b1)\n",
    "print(vectors)\n",
    "vectors = sess.run(W1)\n",
    "print(vectors)\n",
    "vectors = sess.run(W1+b1)\n",
    "print(vectors)\n",
    "print hidden_layer.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>king</td>\n",
       "      <td>0.280912</td>\n",
       "      <td>0.882692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.236663</td>\n",
       "      <td>-0.303961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wise</td>\n",
       "      <td>6.582363</td>\n",
       "      <td>-2.746758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boy</td>\n",
       "      <td>0.456771</td>\n",
       "      <td>1.365885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queen</td>\n",
       "      <td>0.764678</td>\n",
       "      <td>-0.527417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>young</td>\n",
       "      <td>0.064046</td>\n",
       "      <td>0.148715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>princess</td>\n",
       "      <td>6.321781</td>\n",
       "      <td>-0.545915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pretty</td>\n",
       "      <td>4.756935</td>\n",
       "      <td>-3.624880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>girl</td>\n",
       "      <td>1.709406</td>\n",
       "      <td>-0.575898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>strong</td>\n",
       "      <td>2.577764</td>\n",
       "      <td>7.691493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>prince</td>\n",
       "      <td>3.757329</td>\n",
       "      <td>6.749249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>man</td>\n",
       "      <td>2.121614</td>\n",
       "      <td>3.414921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word        x1        x2\n",
       "0       king  0.280912  0.882692\n",
       "1      woman  0.236663 -0.303961\n",
       "2       wise  6.582363 -2.746758\n",
       "3        boy  0.456771  1.365885\n",
       "4      queen  0.764678 -0.527417\n",
       "5      young  0.064046  0.148715\n",
       "6   princess  6.321781 -0.545915\n",
       "7     pretty  4.756935 -3.624880\n",
       "8       girl  1.709406 -0.575898\n",
       "9     strong  2.577764  7.691493\n",
       "10    prince  3.757329  6.749249\n",
       "11       man  2.121614  3.414921"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector in 2d chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1,x2 ))\n",
    "    \n",
    "PADDING = 2.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
